""" This accomplishes the same thing as the selenium crawler, however this method using BeautifulSoup
is way faster. I would definetly reccommend this method. """

''' Libraries '''
from bs4 import BeautifulSoup as soup
import pandas as pd
import requests

''' Scraping Functions '''

def find_data(url):
  first_table = pd.read_html(url)
  return first_table[0]

def sewp(url):
    r = requests.get(url)
    html = soup(r.text, features = 'lxml')
    return html

def find_links(url):
    html = sewp(url)
    href_tags = html.find_all(href = True)
    href_tags = list(href_tags)
    hrefs = [tag.get('href') for tag in href_tags]
    return hrefs
   
   
''' Crawling Function '''
# f5c87b08
# Must enter the 'id' number that is at the end of a teams baseball
# reference page link in order to use this function
def crawl(_id):
    league_links = find_links('https://www.baseball-reference.com/register/league.cgi?id=' + _id)

    # Find team links
    team_links = []
    for href in league_links:
      if '/register/team.cgi?' in href:
        team_links.append(href)
     
    # scrape the team links for the player links
    links_from_team = []
    for href in team_links:
      links_from_team.append(find_links('https://www.baseball-reference.com' + href))
    

    # Append relevant links to list
    player_links = []
    for href in links_from_team:
      for link in href:
        if '/register/player.fcgi?id=' in link:
          player_links.append(link)

    # Get rid of duplicates
    player_links = list(set(player_links))
    
    # finish by Returning the player data to a list
    player_data = []
    for link in player_links:
      player_data.append(find_data('https://www.baseball-reference.com' + link))

    return player_data
    
    
    
 """ Create a dictionary that contains all of the baseball-reference league id's of each year you want to scrape.
     I have an example of what this will look like after the get_league function. You then pass the name of the dictoinary
     into the get_league function and boom. Baseball data baby. """
 
 def get_league(league_yearid_dict):
  all_players = []
  for year in league_yearid_dict.values():
    all_players.append(crawl(year))
  return all_players
  
  
# Example dictionary of bbref league id years that I want to scrape
nwl_yearid_dict = {2021:'f5c87b08',2020:'78f2935d',
                   2019:'817f5f93',2018:'6a2b88b5',
                   2017:'c290e2ac',2016:'b33681e2',2015:'1671dc07'}

# Use this function to make sure we crawled all the right data
def check(list_of_league_data, league_name):
  players = 0
  for i in list_of_league_data:
    num_players = len(i)
    players += num_players
  print(f'Evaluation for {league_name}:')
  print(f'Number of years: {len(list_of_league_data)}')
  print(f'Number of players in league: {players}')
