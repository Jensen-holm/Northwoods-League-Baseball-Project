{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "''' Scraping Libraries '''\n",
    "from bs4 import BeautifulSoup as Soup \n",
    "import pandas as pd\n",
    "import requests"
   ],
   "execution_count":0,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"LEfIGCXr7IXNd54cH1VadE"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# General Scraping Functions"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"Ks7SgVbCswXbJadetaJby9"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "headers = {'User-Agent':'Edge'}\n",
    "\n",
    "def parse_row(rows):\n",
    "    return [str(x.string) for x in rows.find_all('td')]\n",
    "\n",
    "def sewp(url):\n",
    "    r = requests.get(url, headers = headers)\n",
    "    html = Soup(r.text, features = 'lxml')\n",
    "    return html\n",
    "\n",
    "def numeric(frame):\n",
    "    try:\n",
    "        frame[[i]] = frame[[i]].astype(float)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def find_links(url):\n",
    "    html = sewp(url)\n",
    "    href_tags = html.find_all(href = True)\n",
    "    href_tags = list(href_tags)\n",
    "    hrefs = [tag.get('href') for tag in href_tags]\n",
    "    return hrefs"
   ],
   "execution_count":0,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"z40qx7BqR6ebH712nqpCA9"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Baseball Reference Specific Crawling functions"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"YEJZ8VsDssJ5FWDGOpRiIJ"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "''' Baseball Reference Specific Functions '''\n",
    "\n",
    "def find_data(url):\n",
    "    html = sewp(url)\n",
    "    rws = html.find_all('tr')\n",
    "    # Filtering out colligate and NWDS rows\n",
    "    data = []\n",
    "    for row in rws:\n",
    "        row = parse_row(row)\n",
    "        if 'NWDS' in row or 'NAIA' in row or 'NCAA' in row:\n",
    "            data.append(row)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "''' Crawling Function '''\n",
    "def crawl(_id):\n",
    "    league_links = find_links('https:\/\/www.baseball-reference.com\/register\/league.cgi?id=' + _id)\n",
    "\n",
    "    # Find team links\n",
    "    team_links = []\n",
    "    for href in league_links:\n",
    "          if '\/register\/team.cgi?' in href:\n",
    "            team_links.append(href)\n",
    "     \n",
    "    # scrape the team links for the player links\n",
    "    links_from_team = []\n",
    "    for href in team_links:\n",
    "          links_from_team.append(find_links('https:\/\/www.baseball-reference.com' + href))\n",
    "    \n",
    "    # Append relevant links to list\n",
    "    player_links = []\n",
    "    for href in links_from_team:\n",
    "          for link in href:\n",
    "            if '\/register\/player.fcgi?id=' in link:\n",
    "                  player_links.append(link)\n",
    "    \n",
    "    # finish by Returning the player data to a list\n",
    "    player_data = []\n",
    "    for link in player_links:\n",
    "          player_data.append(find_data('https:\/\/www.baseball-reference.com' + link))\n",
    "    \n",
    "    for df in player_data:\n",
    "          numeric(df)\n",
    "\n",
    "    return player_data"
   ],
   "execution_count":0,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"vG1yqkpdKJPv2heOXXyqXh"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Collecting Data"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"bu7kX0l44Kc8k6UhRAYCE1"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "''' Dictionary of league id's from each year we want to crawl '''\n",
    "nwl_yearid_dict = {2021:'f5c87b08',2020:'78f2935d',2019:'817f5f93',2018:'6a2b88b5',\n",
    "                   2017:'c290e2ac',2016:'b33681e2',2015:'1671dc07'}\n",
    "\n",
    "# Gets all years\n",
    "def get_league(league_yearid_dict):\n",
    "    all_players = []\n",
    "    for year in league_yearid_dict.values():\n",
    "        all_players.append(crawl(year))\n",
    "    return all_players\n",
    "\n",
    "# Use this function to see the amount of data we scraped\n",
    "def check(list_of_league_data, league_name):\n",
    "    players = 0\n",
    "    for i in list_of_league_data:\n",
    "        num_players = len(i)\n",
    "        players += num_players\n",
    "    print(f'Evaluation for {league_name}:')\n",
    "    print(f'Number of years: {len(list_of_league_data)}')\n",
    "    print(f'Total number of players: {players}')"
   ],
   "execution_count":0,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"T8uvW8zOGY2pgvDlEQOCpT"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "NWL = get_league(nwl_yearid_dict)\n",
    "print(check(NWL, 'Northwoods League'))"
   ],
   "execution_count":0,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"ICdzch62eXj9ZjGUns9PaT"
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "# Cleaning Data"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"OX4h9KghTgyBJbEh8kGMxM"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "''' Adding Columns '''\n",
    "batting_cols = ['age','age-diff','tm','lg','lev','aff','g','pa','ab','r','h','2b','3b',\n",
    "               'hr','rbi','sb','cs','bb','so','ba','obp','slg','ops','tb','gdp','hbp','sh','sf','ibb']\n",
    "pitching_cols = ['age','age-diff','tm','lg','lev','aff','w','l','w-l','era','ra9','g','gs','gf',\n",
    "                 'cg','sho','sv','ip','h','r','er','hr','bb','ibb','so','hbp','bk','wp','bf','whip','h9',\n",
    "                 'hr9','bb9','so9','so\/bb']\n",
    "\n",
    "# Add columns\n",
    "for lst in NWL:\n",
    "    for df in lst:\n",
    "        if len(df.columns) == 29:\n",
    "            df.columns = batting_cols\n",
    "            df['POS'] = 'Batter'\n",
    "        elif len(df.columns) == 35:\n",
    "            df.columns = pitching_cols\n",
    "            df['POS'] = 'Pitcher'"
   ],
   "execution_count":0,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"EVmF7gJqLLaCCuWPBYclGU"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "''' Organize '''\n",
    "# for some reason index 0 returns an empty list...\n",
    "_1 = NWL[1]\n",
    "_2 = NWL[2]\n",
    "_3 = NWL[3]\n",
    "_4 = NWL[4]\n",
    "_5 = NWL[5]\n",
    "_6 = NWL[6]\n",
    "\n",
    "# finding total number of players (Dataframes)\n",
    "lodfs = [_1, _2, _3, _4, _5, _6]\n",
    "tot_len = 0\n",
    "for x in lodfs:\n",
    "    tot_len += len(x)\n",
    "\n",
    "# using the total number to add a unique number to each player\n",
    "# (doing this b\/c we do not have player names) concat on id column created\n",
    "x = 0\n",
    "while x <= tot_len:\n",
    "    for df in lodfs:\n",
    "        for player in df:\n",
    "            player['id'] = x\n",
    "            x += 1 \n",
    "\n",
    "# Concat based on batters and pitchers\n",
    "def filt(yr):\n",
    "    conc = pd.concat(yr, ignore_index = True)\n",
    "    bat = conc[conc['POS'] == 'Batter']\n",
    "    pitch = conc[conc['POS'] == 'Pitcher']\n",
    "    return bat, pitch\n",
    "\n",
    "# Seperating hitters and pitchers\n",
    "bat_1, pitch_1 = filt(_1)\n",
    "bat_22, pitch_2 = filt(_2)\n",
    "bat_3, pitch_3 = filt(_3)\n",
    "bat_4, pitch_4 = filt(_4)\n",
    "bat_5, pitch_5 = filt(_5)\n",
    "bat_6, pitch_6 = filt(_6)"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"iODPsdqzDFkroysD6Mnx8G"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# seperating colligate and nwds\n",
    "def align(bat, pitch):\n",
    "    naia_bat = []\n",
    "    ncaa_bat = []\n",
    "    nwds_bat = []\n",
    "    nwds_pitch = []\n",
    "    ncaa_pitch = []\n",
    "    naia_pitch = []\n",
    "    # append batting\n",
    "    nwds_bat.append(bat[bat['lev'] == 'Smr'])\n",
    "    ncaa_bat.append(bat[bat['lev'] == 'NCAA'])\n",
    "    naia_bat.append(bat[bat['lev'] == 'NAIA'])\n",
    "    # append pitching\n",
    "    nwds_pitch.append(pitch[pitch['lev'] == 'Smr'])\n",
    "    ncaa_pitch.append(pitch[pitch['lev'] == 'NCAA'])\n",
    "    naia_pitch.append(pitch[pitch['lev'] == 'NAIA'])\n",
    "    # concat\n",
    "    naiabat = pd.concat(naia_bat, ignore_index= True)\n",
    "    ncaabat = pd.concat(ncaa_bat, ignore_index= True)\n",
    "    nwdsbat = pd.concat(nwds_bat, ignore_index= True)\n",
    "    naia_pitch = pd.concat(naia_pitch, ignore_index= True)\n",
    "    ncaa_pitch = pd.concat(ncaa_pitch, ignore_index= True)\n",
    "    nwds_pitch = pd.concat(nwds_pitch, ignore_index= True)\n",
    "    # merge batting\n",
    "    x = pd.merge(ncaabat, nwdsbat, on='id')\n",
    "    y = pd.merge(naiabat, nwdsbat, on='id')\n",
    "    lyst = (x,y)\n",
    "    bat = pd.concat(lyst, ignore_index=True)\n",
    "    # merge pitching\n",
    "    c = pd.merge(ncaa_pitch, nwds_pitch, on='id')\n",
    "    b = pd.merge(naia_pitch, nwds_pitch, on = 'id')\n",
    "    lst = (c,b)\n",
    "    pitch = pd.concat(lst, ignore_index= True)\n",
    "    return bat, pitch\n",
    "\n",
    "bat1, pitch1 = align(bat_1, pitch_1)\n",
    "bat2, pitch2 = align(bat_22, pitch_2)\n",
    "bat3, pitch3 = align(bat_3, pitch_3)\n",
    "bat4, pitch4 = align(bat_4, pitch_4)\n",
    "bat5, pitch5 = align(bat_5, pitch_5)\n",
    "bat6, pitch6 = align(bat_6, pitch_6)\n",
    "\n",
    "bat_list = (bat1, bat2, bat3, bat4, bat5, bat6)\n",
    "pit_list = (pitch1, pitch2, pitch3, pitch4, pitch5, pitch6)\n",
    "\n",
    "# Download these dataframes into excel\n",
    "pitch = pd.concat(pit_list, ignore_index= True)\n",
    "bat = pd.concat(bat_list, ignore_index= True)\n",
    "\n",
    "pitch.to_excel('\/Users\/jense\/Downloads\/crawled_pitch_nwds.xlsx', index = False)\n",
    "bat.to_excel('\/Users\/jense\/Downloads\/crawled_bat_nwds.xlsx', index = False)"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"c5JBm4bMSuJg3ovoGbQdLz"
    }
   }
  }
 ],
 "metadata":{
  "datalore":{
   "version":1,
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ]
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}